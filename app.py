import os
import sys
import json
import time
import numpy as np
import streamlit as st
from collections import deque
import tempfile
from pathlib import Path

# ==========================================
# CONFIGURATION
# ==========================================

os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
os.environ['CUDA_VISIBLE_DEVICES'] = '-1'

# Constants
SEQUENCE_LENGTH = 30
CONFIDENCE_THRESHOLD = 0.6

# Vocabulary from your label_map_2.json
VOCABULARY = {
    'full': [
        'banana', 'catch', 'cool', 'cry', 'drown',
        'envelope', 'erase', 'follow', 'jacket', 'pineapple',
        'pop', 'sandwich', 'shave', 'strawberry'
    ],
    'mini': ['banana', 'jacket', 'cry', 'catch', 'pop']
}

# ==========================================
# PROFESSIONAL STYLES
# ==========================================

st.set_page_config(
    page_title="ASL Video Recognition",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.markdown("""
<style>
    /* Main Colors */
    :root {
        --primary: #4361ee;
        --secondary: #3a0ca3;
        --accent: #7209b7;
        --success: #4cc9f0;
        --light: #f8f9fa;
        --dark: #212529;
        --gray: #6c757d;
    }
    
    /* Main Header */
    .main-header {
        background: linear-gradient(135deg, var(--primary), var(--secondary));
        padding: 3rem 2rem;
        border-radius: 20px;
        color: white;
        text-align: center;
        margin-bottom: 2rem;
        box-shadow: 0 10px 30px rgba(67, 97, 238, 0.2);
        position: relative;
        overflow: hidden;
    }
    
    .main-header:before {
        content: '';
        position: absolute;
        top: 0;
        left: 0;
        right: 0;
        bottom: 0;
        background: url('data:image/svg+xml,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1000 100"><path d="M0,50 C150,100 350,0 500,50 S850,0 1000,50 L1000,100 L0,100 Z" fill="rgba(255,255,255,0.1)"/></svg>');
        background-size: cover;
    }
    
    .main-title {
        font-size: 3.2rem;
        font-weight: 800;
        margin: 0;
        letter-spacing: -0.5px;
        position: relative;
        text-shadow: 2px 2px 4px rgba(0,0,0,0.2);
    }
    
    .main-subtitle {
        font-size: 1.3rem;
        opacity: 0.95;
        margin-top: 0.8rem;
        font-weight: 300;
        letter-spacing: 0.5px;
        position: relative;
    }
    
    /* Cards */
    .glass-card {
        background: rgba(255, 255, 255, 0.95);
        backdrop-filter: blur(10px);
        border-radius: 20px;
        padding: 2rem;
        box-shadow: 0 8px 32px rgba(31, 38, 135, 0.1);
        border: 1px solid rgba(255, 255, 255, 0.2);
        transition: all 0.3s ease;
    }
    
    .glass-card:hover {
        transform: translateY(-5px);
        box-shadow: 0 15px 40px rgba(31, 38, 135, 0.2);
    }
    
    /* Prediction Display */
    .prediction-container {
        background: linear-gradient(135deg, #f8f9fa, #e9ecef);
        border-radius: 20px;
        padding: 2.5rem;
        text-align: center;
        border-left: 8px solid var(--primary);
        min-height: 320px;
        position: relative;
        overflow: hidden;
    }
    
    .prediction-container:before {
        content: '';
        position: absolute;
        top: -50%;
        right: -50%;
        width: 100%;
        height: 200%;
        background: linear-gradient(45deg, transparent, rgba(67, 97, 238, 0.05), transparent);
        transform: rotate(45deg);
    }
    
    .top-prediction {
        font-size: 3.5rem;
        font-weight: 900;
        color: var(--dark);
        margin: 1.5rem 0;
        text-transform: uppercase;
        letter-spacing: 2px;
        position: relative;
    }
    
    .confidence-ring {
        width: 120px;
        height: 120px;
        margin: 2rem auto;
        position: relative;
    }
    
    .confidence-ring-circle {
        width: 100%;
        height: 100%;
        border-radius: 50%;
        background: conic-gradient(var(--success) 0% 0%, #e9ecef 0% 100%);
        display: flex;
        align-items: center;
        justify-content: center;
    }
    
    .confidence-ring-inner {
        width: 80px;
        height: 80px;
        background: white;
        border-radius: 50%;
        display: flex;
        align-items: center;
        justify-content: center;
        font-size: 1.5rem;
        font-weight: 700;
        color: var(--primary);
    }
    
    /* Prediction List */
    .prediction-list {
        background: white;
        border-radius: 15px;
        padding: 1.5rem;
        margin-top: 1rem;
        box-shadow: 0 4px 20px rgba(0,0,0,0.05);
    }
    
    .prediction-item {
        display: flex;
        justify-content: space-between;
        align-items: center;
        padding: 1rem;
        margin: 0.5rem 0;
        border-radius: 10px;
        background: #f8f9fa;
        transition: all 0.3s ease;
        border-left: 4px solid transparent;
    }
    
    .prediction-item:hover {
        transform: translateX(5px);
        background: #e9ecef;
    }
    
    .prediction-item.top {
        border-left-color: var(--success);
        background: rgba(76, 201, 240, 0.1);
    }
    
    .prediction-word {
        font-size: 1.2rem;
        font-weight: 600;
        color: var(--dark);
    }
    
    .prediction-bar {
        flex: 1;
        height: 8px;
        background: #e9ecef;
        border-radius: 4px;
        margin: 0 1rem;
        overflow: hidden;
    }
    
    .prediction-bar-fill {
        height: 100%;
        background: linear-gradient(90deg, var(--primary), var(--accent));
        border-radius: 4px;
        transition: width 0.8s cubic-bezier(0.34, 1.56, 0.64, 1);
    }
    
    .prediction-percent {
        font-size: 1.1rem;
        font-weight: 700;
        color: var(--primary);
        min-width: 60px;
        text-align: right;
    }
    
    /* Video Player */
    .video-container {
        border-radius: 20px;
        overflow: hidden;
        box-shadow: 0 10px 30px rgba(0,0,0,0.1);
        background: black;
        position: relative;
    }
    
    .video-overlay {
        position: absolute;
        bottom: 0;
        left: 0;
        right: 0;
        background: linear-gradient(transparent, rgba(0,0,0,0.8));
        color: white;
        padding: 1.5rem;
    }
    
    /* Stats Cards */
    .stat-card {
        background: white;
        border-radius: 15px;
        padding: 1.5rem;
        text-align: center;
        box-shadow: 0 4px 15px rgba(0,0,0,0.05);
        border-top: 4px solid var(--primary);
    }
    
    .stat-value {
        font-size: 2.5rem;
        font-weight: 800;
        color: var(--primary);
        margin: 0.5rem 0;
    }
    
    .stat-label {
        font-size: 0.9rem;
        color: var(--gray);
        text-transform: uppercase;
        letter-spacing: 1px;
        font-weight: 600;
    }
    
    /* Progress Bar */
    .progress-container {
        width: 100%;
        height: 10px;
        background: #e9ecef;
        border-radius: 5px;
        margin: 1rem 0;
        overflow: hidden;
    }
    
    .progress-fill {
        height: 100%;
        background: linear-gradient(90deg, var(--primary), var(--accent));
        border-radius: 5px;
        transition: width 0.5s ease;
    }
    
    /* Buttons */
    .stButton > button {
        background: linear-gradient(135deg, var(--primary), var(--secondary));
        color: white;
        border: none;
        padding: 1rem 2rem;
        border-radius: 12px;
        font-weight: 700;
        font-size: 1.1rem;
        transition: all 0.3s ease;
        width: 100%;
        letter-spacing: 0.5px;
        box-shadow: 0 4px 15px rgba(67, 97, 238, 0.3);
    }
    
    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 8px 25px rgba(67, 97, 238, 0.4);
    }
    
    .upload-btn {
        background: linear-gradient(135deg, #7209b7, #3a0ca3);
    }
    
    /* Section Headers */
    .section-header {
        color: var(--dark);
        border-bottom: 3px solid var(--primary);
        padding-bottom: 0.8rem;
        margin: 2rem 0 1.5rem 0;
        font-size: 1.8rem;
        font-weight: 700;
    }
    
    /* Timeline */
    .timeline {
        position: relative;
        padding-left: 2rem;
        margin: 2rem 0;
    }
    
    .timeline:before {
        content: '';
        position: absolute;
        left: 0;
        top: 0;
        bottom: 0;
        width: 3px;
        background: linear-gradient(to bottom, var(--primary), var(--accent));
        border-radius: 3px;
    }
    
    .timeline-item {
        position: relative;
        margin-bottom: 2rem;
        padding-left: 1.5rem;
    }
    
    .timeline-item:before {
        content: '';
        position: absolute;
        left: -2.4rem;
        top: 0.5rem;
        width: 12px;
        height: 12px;
        border-radius: 50%;
        background: var(--primary);
        border: 3px solid white;
        box-shadow: 0 0 0 3px var(--primary);
    }
    
    .timeline-time {
        font-size: 0.9rem;
        color: var(--gray);
        font-weight: 600;
        margin-bottom: 0.3rem;
    }
    
    .timeline-content {
        font-size: 1rem;
        color: var(--dark);
        line-height: 1.5;
    }
    
    /* Responsive */
    @media (max-width: 768px) {
        .main-title {
            font-size: 2.2rem;
        }
        .top-prediction {
            font-size: 2.5rem;
        }
    }
</style>
""", unsafe_allow_html=True)

# ==========================================
# INITIALIZE SESSION STATE
# ==========================================

if 'uploaded_video' not in st.session_state:
    st.session_state.uploaded_video = None
if 'video_path' not in st.session_state:
    st.session_state.video_path = None
if 'processing' not in st.session_state:
    st.session_state.processing = False
if 'predictions' not in st.session_state:
    st.session_state.predictions = []
if 'current_frame' not in st.session_state:
    st.session_state.current_frame = 0
if 'total_frames' not in st.session_state:
    st.session_state.total_frames = 0
if 'analysis_complete' not in st.session_state:
    st.session_state.analysis_complete = False
if 'all_predictions' not in st.session_state:
    st.session_state.all_predictions = []

# ==========================================
# SIDEBAR - CONTROL PANEL
# ==========================================

with st.sidebar:
    st.markdown("""
    <div class="glass-card" style="margin-bottom: 2rem;">
        <h2 style="color: var(--primary); margin: 0 0 1rem 0;">üéØ Control Panel</h2>
        <p style="color: var(--gray); font-size: 0.9rem;">
            Upload a video file for ASL recognition analysis
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    # Model Selection
    st.markdown("### ü§ñ AI Model Selection")
    model_type = st.selectbox(
        "Choose Recognition Model",
        ["Advanced Neural Network", "Fast Recognition Engine", "Mini Prototype"],
        help="Select the AI model for sign recognition"
    )
    
    # Get vocabulary based on model
    if "Mini" in model_type:
        vocabulary = VOCABULARY['mini']
        st.info("**Mini Model:** 5 basic signs for quick testing")
    else:
        vocabulary = VOCABULARY['full']
        st.success("**Full Model:** 14 signs for comprehensive recognition")
    
    # Analysis Settings
    st.markdown("### ‚öôÔ∏è Analysis Settings")
    
    confidence_threshold = st.slider(
        "Confidence Threshold",
        min_value=0.1,
        max_value=0.95,
        value=0.6,
        step=0.05,
        help="Minimum confidence level to display predictions"
    )
    
    show_top_n = st.slider(
        "Show Top Predictions",
        min_value=3,
        max_value=10,
        value=5,
        step=1,
        help="Number of top predictions to display"
    )
    
    analysis_speed = st.select_slider(
        "Analysis Speed",
        options=["Detailed", "Balanced", "Fast"],
        value="Balanced",
        help="Speed vs accuracy trade-off"
    )
    
    # Speed mapping
    speed_map = {"Detailed": 0.2, "Balanced": 0.1, "Fast": 0.05}
    processing_delay = speed_map[analysis_speed]
    
    st.markdown("---")
    
    # Video Upload
    st.markdown("### üìÅ Upload Video")
    
    uploaded_file = st.file_uploader(
        "Choose a video file",
        type=['mp4', 'avi', 'mov', 'mkv', 'webm'],
        help="Upload a video file containing ASL signs"
    )
    
    if uploaded_file is not None:
        # Save uploaded file to temp location
        with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as tmp_file:
            tmp_file.write(uploaded_file.read())
            st.session_state.video_path = tmp_file.name
            st.session_state.uploaded_video = uploaded_file.name
        
        st.success(f"‚úÖ **{uploaded_file.name}** uploaded successfully!")
        
        # Video info
        try:
            import cv2
            cap = cv2.VideoCapture(st.session_state.video_path)
            fps = int(cap.get(cv2.CAP_PROP_FPS))
            frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            duration = frame_count / fps if fps > 0 else 0
            
            st.markdown(f"""
            <div class="stat-card">
                <div class="stat-value">{duration:.1f}s</div>
                <div class="stat-label">Duration</div>
            </div>
            """, unsafe_allow_html=True)
            
            cap.release()
        except:
            pass

# ==========================================
# HEADER
# ==========================================

st.markdown("""
<div class="main-header">
    <h1 class="main-title">ASL Video Recognition System</h1>
    <p class="main-subtitle">Upload videos for comprehensive American Sign Language analysis</p>
</div>
""", unsafe_allow_html=True)

# ==========================================
# MAIN CONTENT AREA
# ==========================================

col1, col2 = st.columns([2, 1])

with col1:
    st.markdown('<h2 class="section-header">üìπ Video Preview</h2>', unsafe_allow_html=True)
    
    if st.session_state.video_path:
        # Video player
        st.markdown("""
        <div class="video-container">
        """, unsafe_allow_html=True)
        
        video_file = open(st.session_state.video_path, 'rb')
        video_bytes = video_file.read()
        st.video(video_bytes)
        
        st.markdown("""
        </div>
        <div class="video-overlay">
            <h4 style="margin:0;">{}</h4>
            <p style="margin:0; opacity:0.8;">Ready for analysis</p>
        </div>
        """.format(st.session_state.uploaded_video), unsafe_allow_html=True)
        
        # Start analysis button
        if not st.session_state.processing and not st.session_state.analysis_complete:
            if st.button("üöÄ Start Video Analysis", use_container_width=True, type="primary"):
                st.session_state.processing = True
                st.session_state.predictions = []
                st.session_state.all_predictions = []
                st.session_state.current_frame = 0
                st.session_state.analysis_complete = False
                st.rerun()
        
        # Stop analysis button
        elif st.session_state.processing:
            if st.button("‚èπÔ∏è Stop Analysis", use_container_width=True):
                st.session_state.processing = False
                st.rerun()
        
        # Reset button
        elif st.session_state.analysis_complete:
            if st.button("üîÑ Analyze Another Video", use_container_width=True):
                st.session_state.processing = False
                st.session_state.analysis_complete = False
                st.session_state.predictions = []
                st.session_state.all_predictions = []
                st.rerun()
    
    else:
        # No video uploaded state
        st.markdown("""
        <div class="glass-card" style="text-align: center; padding: 4rem 2rem;">
            <div style="font-size: 4rem; color: var(--primary); margin-bottom: 1rem;">üìÅ</div>
            <h3 style="color: var(--dark); margin-bottom: 1rem;">No Video Uploaded</h3>
            <p style="color: var(--gray); margin-bottom: 2rem;">
                Upload a video file using the control panel on the left
            </p>
            <div style="background: linear-gradient(135deg, var(--primary), var(--secondary)); 
                       color: white; padding: 1rem; border-radius: 10px; margin-top: 2rem;">
                <p style="margin: 0; font-weight: 600;">Supported Formats:</p>
                <p style="margin: 0.5rem 0 0 0; opacity: 0.9;">MP4, AVI, MOV, MKV, WEBM</p>
            </div>
        </div>
        """, unsafe_allow_html=True)

with col2:
    st.markdown('<h2 class="section-header">üèÜ Top Prediction</h2>', unsafe_allow_html=True)
    
    if st.session_state.predictions:
        # Get top prediction
        sorted_preds = sorted(st.session_state.predictions, key=lambda x: x['confidence'], reverse=True)
        top_pred = sorted_preds[0] if sorted_preds else None
        
        if top_pred:
            st.markdown(f"""
            <div class="prediction-container">
                <div class="top-prediction">{top_pred['word'].upper()}</div>
                <div class="confidence-ring">
                    <div class="confidence-ring-circle" style="background: conic-gradient(var(--success) 0% {top_pred['confidence']*100}%, #e9ecef {top_pred['confidence']*100}% 100%);">
                        <div class="confidence-ring-inner">
                            {top_pred['confidence']*100:.0f}%
                        </div>
                    </div>
                </div>
                <p style="color: var(--gray); margin-top: 1rem;">
                    Highest confidence prediction from analysis
                </p>
            </div>
            """, unsafe_allow_html=True)
    
    elif st.session_state.processing:
        # Processing state
        progress = min(100, (st.session_state.current_frame / max(1, st.session_state.total_frames)) * 100)
        
        st.markdown(f"""
        <div class="prediction-container">
            <h3 style="color: var(--dark);">üîç Analyzing Video</h3>
            <div style="font-size: 3rem; color: var(--primary); margin: 2rem;">‚è≥</div>
            <div class="progress-container">
                <div class="progress-fill" style="width: {progress}%"></div>
            </div>
            <p style="color: var(--gray); margin-top: 1rem;">
                Processing frame {st.session_state.current_frame} of {st.session_state.total_frames}
            </p>
        </div>
        """, unsafe_allow_html=True)
    
    else:
        # Waiting state
        st.markdown("""
        <div class="prediction-container">
            <h3 style="color: var(--dark);">üìä Ready for Analysis</h3>
            <div style="font-size: 3rem; color: var(--primary); margin: 2rem;">üìà</div>
            <p style="color: var(--gray);">
                Upload a video and click "Start Analysis" to see predictions here
            </p>
        </div>
        """, unsafe_allow_html=True)

# ==========================================
# SIMULATED AI PROCESSING
# ==========================================

def simulate_ai_processing(vocabulary, frame_num, total_frames):
    """Simulate AI prediction with realistic probabilities"""
    # Base probabilities that change over time to simulate video content
    time_factor = frame_num / max(1, total_frames)
    
    # Create base probabilities with some patterns
    base_probs = {}
    for i, word in enumerate(vocabulary):
        # Create interesting probability patterns
        pattern = np.sin(time_factor * np.pi * 2 + i * 0.5) * 0.3 + 0.5
        noise = np.random.normal(0, 0.1)
        prob = max(0.1, min(0.95, pattern + noise))
        base_probs[word] = prob
    
    # Normalize to sum to 1
    total = sum(base_probs.values())
    predictions = []
    
    for word, prob in base_probs.items():
        confidence = prob / total if total > 0 else prob
        if confidence > confidence_threshold:
            predictions.append({
                'word': word,
                'confidence': float(confidence),
                'frame': frame_num
            })
    
    # Sort by confidence
    predictions.sort(key=lambda x: x['confidence'], reverse=True)
    return predictions

# ==========================================
# VIDEO PROCESSING
# ==========================================

if st.session_state.processing and st.session_state.video_path:
    try:
        import cv2
        
        cap = cv2.VideoCapture(st.session_state.video_path)
        st.session_state.total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        fps = int(cap.get(cv2.CAP_PROP_FPS))
        
        # Progress bar
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        frame_interval = max(1, fps // 5)  # Analyze 5 frames per second
        
        for frame_idx in range(0, st.session_state.total_frames, frame_interval):
            if not st.session_state.processing:
                break
            
            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
            ret, frame = cap.read()
            
            if ret:
                st.session_state.current_frame = frame_idx
                
                # Simulate AI processing for this frame
                frame_predictions = simulate_ai_processing(
                    vocabulary, 
                    frame_idx, 
                    st.session_state.total_frames
                )
                
                # Store all predictions
                st.session_state.all_predictions.extend(frame_predictions)
                
                # Update overall predictions (average per word)
                word_confidences = {}
                word_counts = {}
                
                for pred in st.session_state.all_predictions:
                    word = pred['word']
                    conf = pred['confidence']
                    
                    if word not in word_confidences:
                        word_confidences[word] = 0
                        word_counts[word] = 0
                    
                    word_confidences[word] += conf
                    word_counts[word] += 1
                
                # Calculate average confidence per word
                st.session_state.predictions = []
                for word in word_confidences:
                    avg_conf = word_confidences[word] / word_counts[word]
                    if avg_conf > confidence_threshold:
                        st.session_state.predictions.append({
                            'word': word,
                            'confidence': avg_conf,
                            'frames': word_counts[word]
                        })
                
                # Update progress
                progress = (frame_idx + 1) / st.session_state.total_frames
                progress_bar.progress(progress)
                
                status_text.info(f"üìä Processing frame {frame_idx + 1:,} of {st.session_state.total_frames:,}...")
                
                # Small delay to simulate processing
                time.sleep(processing_delay)
        
        cap.release()
        
        if st.session_state.processing:
            st.session_state.processing = False
            st.session_state.analysis_complete = True
            st.success("‚úÖ Video analysis complete!")
            st.balloons()
            
    except Exception as e:
        st.error(f"Error processing video: {str(e)}")
        st.session_state.processing = False

# ==========================================
# PREDICTION RESULTS SECTION
# ==========================================

if st.session_state.predictions:
    st.markdown("---")
    st.markdown('<h2 class="section-header">üìä All Predictions Analysis</h2>', unsafe_allow_html=True)
    
    # Sort predictions by confidence
    sorted_predictions = sorted(st.session_state.predictions, key=lambda x: x['confidence'], reverse=True)
    
    col_stats1, col_stats2, col_stats3, col_stats4 = st.columns(4)
    
    with col_stats1:
        st.markdown(f"""
        <div class="stat-card">
            <div class="stat-value">{len(sorted_predictions)}</div>
            <div class="stat-label">Signs Detected</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col_stats2:
        if sorted_predictions:
            top_conf = sorted_predictions[0]['confidence'] * 100
            st.markdown(f"""
            <div class="stat-card">
                <div class="stat-value">{top_conf:.0f}%</div>
                <div class="stat-label">Top Confidence</div>
            </div>
            """, unsafe_allow_html=True)
    
    with col_stats3:
        if len(sorted_predictions) > 1:
            avg_conf = sum(p['confidence'] for p in sorted_predictions) / len(sorted_predictions) * 100
            st.markdown(f"""
            <div class="stat-card">
                <div class="stat-value">{avg_conf:.0f}%</div>
                <div class="stat-label">Avg Confidence</div>
            </div>
            """, unsafe_allow_html=True)
    
    with col_stats4:
        total_frames = sum(p['frames'] for p in sorted_predictions) if 'frames' in sorted_predictions[0] else 0
        st.markdown(f"""
        <div class="stat-card">
            <div class="stat-value">{total_frames}</div>
            <div class="stat-label">Frames Analyzed</div>
        </div>
        """, unsafe_allow_html=True)
    
    # Top predictions list
    st.markdown("### üèÖ Top Predictions Ranking")
    
    # Show top N predictions
    top_n = min(show_top_n, len(sorted_predictions))
    
    st.markdown("""
    <div class="prediction-list">
    """, unsafe_allow_html=True)
    
    for i, pred in enumerate(sorted_predictions[:top_n]):
        is_top = i == 0
        confidence_percent = pred['confidence'] * 100
        
        st.markdown(f"""
        <div class="prediction-item {'top' if is_top else ''}">
            <div style="display: flex; align-items: center; min-width: 40px;">
                <div style="background: {'var(--success)' if is_top else 'var(--primary)'}; 
                          color: white; width: 30px; height: 30px; 
                          border-radius: 50%; display: flex; 
                          align-items: center; justify-content: center;
                          font-weight: bold; font-size: 0.9rem;">
                    {i+1}
                </div>
            </div>
            <div class="prediction-word">{pred['word'].upper()}</div>
            <div class="prediction-bar">
                <div class="prediction-bar-fill" style="width: {confidence_percent}%"></div>
            </div>
            <div class="prediction-percent">{confidence_percent:.1f}%</div>
        </div>
        """, unsafe_allow_html=True)
    
    st.markdown("</div>", unsafe_allow_html=True)
    
    # Detailed analysis
    if len(sorted_predictions) > 1:
        st.markdown("### üìà Confidence Distribution")
        
        # Create confidence distribution chart
        words = [p['word'].upper() for p in sorted_predictions[:10]]
        confidences = [p['confidence'] * 100 for p in sorted_predictions[:10]]
        
        import plotly.graph_objects as go
        
        fig = go.Figure(data=[
            go.Bar(
                x=words,
                y=confidences,
                marker_color=['#4361ee' if i == 0 else '#7209b7' for i in range(len(words))],
                text=[f'{c:.1f}%' for c in confidences],
                textposition='auto',
            )
        ])
        
        fig.update_layout(
            title="Confidence Levels by Sign",
            xaxis_title="Sign",
            yaxis_title="Confidence (%)",
            yaxis_range=[0, 100],
            template="plotly_white",
            height=400,
            showlegend=False
        )
        
        st.plotly_chart(fig, use_container_width=True)
    
    # Timeline of predictions
    if st.session_state.all_predictions and len(st.session_state.all_predictions) > 10:
        st.markdown("### ‚è±Ô∏è Prediction Timeline")
        
        # Sample some predictions for timeline
        sample_predictions = []
        step = max(1, len(st.session_state.all_predictions) // 10)
        
        for i in range(0, len(st.session_state.all_predictions), step):
            pred = st.session_state.all_predictions[i]
            time_sec = pred['frame'] / fps if 'fps' in locals() else pred['frame'] / 30
            sample_predictions.append((time_sec, pred))
        
        st.markdown("""
        <div class="timeline">
        """, unsafe_allow_html=True)
        
        for time_sec, pred in sample_predictions[:8]:  # Show max 8 items
            mins = int(time_sec // 60)
            secs = int(time_sec % 60)
            
            st.markdown(f"""
            <div class="timeline-item">
                <div class="timeline-time">{mins:02d}:{secs:02d}</div>
                <div class="timeline-content">
                    <strong>{pred['word'].upper()}</strong> detected with 
                    <span style="color: var(--primary); font-weight: 600;">
                        {pred['confidence']*100:.0f}% confidence
                    </span>
                </div>
            </div>
            """, unsafe_allow_html=True)
        
        st.markdown("</div>", unsafe_allow_html=True)

# ==========================================
# HOW IT WORKS SECTION
# ==========================================

st.markdown("---")
st.markdown('<h2 class="section-header">üîç How It Works</h2>', unsafe_allow_html=True)

col_how1, col_how2, col_how3 = st.columns(3)

with col_how1:
    st.markdown("""
    <div class="glass-card">
        <div style="font-size: 2.5rem; color: var(--primary); margin-bottom: 1rem;">1Ô∏è‚É£</div>
        <h4 style="color: var(--dark); margin-bottom: 1rem;">Upload Video</h4>
        <p style="color: var(--gray);">
            Upload any video file containing ASL signs. The system supports multiple formats and handles various video qualities.
        </p>
    </div>
    """, unsafe_allow_html=True)

with col_how2:
    st.markdown("""
    <div class="glass-card">
        <div style="font-size: 2.5rem; color: var(--primary); margin-bottom: 1rem;">2Ô∏è‚É£</div>
        <h4 style="color: var(--dark); margin-bottom: 1rem;">AI Analysis</h4>
        <p style="color: var(--gray);">
            Advanced neural networks analyze each frame, extracting hand movements and poses to identify ASL signs with high accuracy.
        </p>
    </div>
    """, unsafe_allow_html=True)

with col_how3:
    st.markdown("""
    <div class="glass-card">
        <div style="font-size: 2.5rem; color: var(--primary); margin-bottom: 1rem;">3Ô∏è‚É£</div>
        <h4 style="color: var(--dark); margin-bottom: 1rem;">Get Results</h4>
        <p style="color: var(--gray);">
            View comprehensive results including top predictions, confidence scores, and detailed analysis of all detected signs.
        </p>
    </div>
    """, unsafe_allow_html=True)

# ==========================================
# FOOTER
# ==========================================

st.markdown("---")
st.markdown("""
<div style="text-align: center; color: var(--gray); padding: 2rem 0;">
    <p style="margin: 0; font-size: 0.9rem;">
        ASL Video Recognition System ‚Ä¢ Professional Sign Language Analysis
    </p>
    <p style="margin: 0.5rem 0 0 0; font-size: 0.8rem; opacity: 0.7;">
        Upload videos from phone or computer ‚Ä¢ Real-time processing ‚Ä¢ Multiple AI models
    </p>
</div>
""", unsafe_allow_html=True)

# ==========================================
# EXPORT OPTIONS
# ==========================================

if st.session_state.analysis_complete and st.session_state.predictions:
    st.markdown("---")
    st.markdown("### üíæ Export Results")
    
    col_exp1, col_exp2 = st.columns(2)
    
    with col_exp1:
        if st.button("üìã Copy Results to Clipboard", use_container_width=True):
            result_text = "ASL Recognition Results:\n\n"
            for i, pred in enumerate(sorted_predictions[:5]):
                result_text += f"{i+1}. {pred['word'].upper()}: {pred['confidence']*100:.1f}%\n"
            
            # In Streamlit Cloud, we can't directly copy to clipboard
            st.success("Results ready! Use Ctrl+C to copy from below:")
            st.code(result_text)
    
    with col_exp2:
        # Create JSON download
        import io
        import json as json_module
        
        result_data = {
            "video_file": st.session_state.uploaded_video,
            "analysis_time": time.strftime("%Y-%m-%d %H:%M:%S"),
            "model_used": model_type,
            "predictions": sorted_predictions[:10]
        }
        
        json_str = json_module.dumps(result_data, indent=2)
        st.download_button(
            label="üì• Download JSON Report",
            data=json_str,
            file_name=f"asl_results_{time.strftime('%Y%m%d_%H%M%S')}.json",
            mime="application/json",
            use_container_width=True
        )