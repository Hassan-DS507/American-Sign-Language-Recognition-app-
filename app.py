import os
import json
import time
import numpy as np
import streamlit as st
import tempfile
import cv2
from collections import deque

# ==========================================
# CONFIGURATION
# ==========================================

os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
os.environ['CUDA_VISIBLE_DEVICES'] = '-1'

# Force disable MediaPipe model downloads (prevents errors)
os.environ['MEDIAPIPE_DISABLE_MODEL_DOWNLOAD'] = '1'

# Constants
SEQUENCE_LENGTH = 30
CONFIDENCE_THRESHOLD = 0.6

# Model configurations
MODELS = {
    "Bi-LSTM Neural Network": {
        "type": "deep_learning",
        "vocabulary": 'full',
        "accuracy": "87.86%",
        "description": "Advanced bidirectional LSTM for complex temporal patterns",
        "file": "bilstm_model_2.keras"
    },
    "XGBoost Classifier": {
        "type": "machine_learning",
        "vocabulary": 'full',
        "accuracy": "79.56%",
        "description": "Fast gradient boosting for distinct poses",
        "file": "xgboost_asl.pkl"
    },
    "Mini XGBoost (Demo)": {
        "type": "machine_learning",
        "vocabulary": 'mini',
        "accuracy": "92.34%",
        "description": "Lightweight model for 5 basic signs",
        "file": "xgb_model.pkl"
    }
}

# Vocabulary from your label_map_2.json
VOCABULARY = {
    'full': [
        'banana', 'catch', 'cool', 'cry', 'drown',
        'envelope', 'erase', 'follow', 'jacket', 'pineapple',
        'pop', 'sandwich', 'shave', 'strawberry'
    ],
    'mini': ['banana', 'jacket', 'cry', 'catch', 'pop']
}

# ==========================================
# SIMPLE CSS - CLEAN AND PROFESSIONAL
# ==========================================

st.set_page_config(
    page_title="ASL Video Recognition",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.markdown("""
<style>
    /* Reset and base styles */
    * {
        margin: 0;
        padding: 0;
        box-sizing: border-box;
    }
    
    body {
        font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
    }
    
    /* Main container */
    .main-container {
        max-width: 1400px;
        margin: 0 auto;
        padding: 20px;
    }
    
    /* Header */
    .header-section {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 30px;
        border-radius: 15px;
        margin-bottom: 30px;
        text-align: center;
        box-shadow: 0 10px 30px rgba(102, 126, 234, 0.2);
    }
    
    .main-title {
        font-size: 2.8rem;
        font-weight: 800;
        margin-bottom: 10px;
    }
    
    .sub-title {
        font-size: 1.2rem;
        opacity: 0.95;
        font-weight: 300;
    }
    
    /* Model Info Card */
    .model-card {
        background: white;
        border-radius: 12px;
        padding: 20px;
        margin-bottom: 20px;
        border-left: 5px solid #667eea;
        box-shadow: 0 4px 15px rgba(0,0,0,0.08);
    }
    
    .model-name {
        font-size: 1.4rem;
        font-weight: 700;
        color: #2d3748;
        margin-bottom: 8px;
    }
    
    .model-stats {
        display: flex;
        gap: 15px;
        margin-bottom: 10px;
    }
    
    .model-stat {
        font-size: 0.9rem;
        color: #718096;
    }
    
    .model-stat strong {
        color: #667eea;
    }
    
    /* Video container */
    .video-container {
        background: #000;
        border-radius: 12px;
        overflow: hidden;
        margin-bottom: 20px;
        box-shadow: 0 8px 25px rgba(0,0,0,0.15);
        position: relative;
    }
    
    .video-overlay {
        position: absolute;
        bottom: 0;
        left: 0;
        right: 0;
        background: linear-gradient(transparent, rgba(0,0,0,0.8));
        color: white;
        padding: 15px;
        font-size: 0.9rem;
    }
    
    /* Results */
    .results-container {
        background: #f8f9fa;
        border-radius: 12px;
        padding: 25px;
        border-left: 5px solid #667eea;
        margin-bottom: 20px;
    }
    
    .top-prediction {
        text-align: center;
        margin-bottom: 25px;
    }
    
    .top-word {
        font-size: 3rem;
        font-weight: 900;
        color: #2d3748;
        margin: 10px 0;
        text-transform: uppercase;
        letter-spacing: 1px;
    }
    
    .top-confidence {
        font-size: 1.5rem;
        color: #38a169;
        font-weight: 700;
    }
    
    /* Prediction List */
    .prediction-list {
        background: white;
        border-radius: 10px;
        padding: 0;
        overflow: hidden;
    }
    
    .prediction-item {
        display: flex;
        align-items: center;
        padding: 18px 20px;
        border-bottom: 1px solid #e9ecef;
        transition: background 0.2s;
    }
    
    .prediction-item:hover {
        background: #f8f9fa;
    }
    
    .prediction-item:last-child {
        border-bottom: none;
    }
    
    .prediction-rank {
        width: 36px;
        height: 36px;
        background: #667eea;
        color: white;
        border-radius: 50%;
        display: flex;
        align-items: center;
        justify-content: center;
        font-weight: 700;
        margin-right: 15px;
        flex-shrink: 0;
    }
    
    .prediction-content {
        flex: 1;
        min-width: 0;
    }
    
    .prediction-word {
        font-size: 1.3rem;
        font-weight: 600;
        color: #2d3748;
        margin-bottom: 4px;
    }
    
    .prediction-bar-container {
        height: 8px;
        background: #e9ecef;
        border-radius: 4px;
        overflow: hidden;
        margin: 8px 0;
    }
    
    .prediction-bar {
        height: 100%;
        background: linear-gradient(90deg, #667eea, #764ba2);
        border-radius: 4px;
        transition: width 0.5s ease;
    }
    
    .prediction-confidence {
        font-size: 1rem;
        color: #718096;
        font-weight: 600;
    }
    
    /* Progress */
    .progress-container {
        width: 100%;
        height: 10px;
        background: #e9ecef;
        border-radius: 5px;
        margin: 20px 0;
        overflow: hidden;
    }
    
    .progress-fill {
        height: 100%;
        background: linear-gradient(90deg, #667eea, #764ba2);
        border-radius: 5px;
        transition: width 0.3s ease;
    }
    
    /* Stats */
    .stats-grid {
        display: grid;
        grid-template-columns: repeat(2, 1fr);
        gap: 15px;
        margin: 25px 0;
    }
    
    @media (min-width: 768px) {
        .stats-grid {
            grid-template-columns: repeat(4, 1fr);
        }
    }
    
    .stat-box {
        background: white;
        padding: 20px;
        border-radius: 10px;
        text-align: center;
        border-top: 4px solid #667eea;
        box-shadow: 0 3px 10px rgba(0,0,0,0.05);
    }
    
    .stat-value {
        font-size: 2rem;
        font-weight: 800;
        color: #2d3748;
        margin: 5px 0;
    }
    
    .stat-label {
        font-size: 0.85rem;
        color: #718096;
        text-transform: uppercase;
        letter-spacing: 0.5px;
        font-weight: 600;
    }
    
    /* Buttons */
    .stButton > button {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border: none;
        padding: 14px 28px;
        border-radius: 10px;
        font-weight: 600;
        font-size: 1rem;
        width: 100%;
        cursor: pointer;
        transition: transform 0.2s, box-shadow 0.2s;
    }
    
    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 6px 20px rgba(102, 126, 234, 0.3);
    }
    
    /* MediaPipe Info */
    .mediapipe-info {
        background: #e3f2fd;
        border-radius: 10px;
        padding: 15px;
        margin: 15px 0;
        border-left: 4px solid #2196f3;
        font-size: 0.9rem;
        color: #1565c0;
    }
    
    /* Responsive */
    @media (max-width: 768px) {
        .main-title {
            font-size: 2.2rem;
        }
        .top-word {
            font-size: 2.2rem;
        }
    }
    
    /* Force light mode */
    .stApp {
        background-color: white !important;
    }
    
    /* Hide Streamlit branding */
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    header {visibility: hidden;}
</style>
""", unsafe_allow_html=True)

# ==========================================
# INITIALIZE SESSION STATE
# ==========================================

if 'video_file' not in st.session_state:
    st.session_state.video_file = None
if 'video_path' not in st.session_state:
    st.session_state.video_path = None
if 'processing' not in st.session_state:
    st.session_state.processing = False
if 'predictions' not in st.session_state:
    st.session_state.predictions = []
if 'analysis_complete' not in st.session_state:
    st.session_state.analysis_complete = False
if 'current_progress' not in st.session_state:
    st.session_state.current_progress = 0
if 'selected_model' not in st.session_state:
    st.session_state.selected_model = "Bi-LSTM Neural Network"
if 'mediapipe_available' not in st.session_state:
    st.session_state.mediapipe_available = False

# ==========================================
# SIMULATED AI PROCESSING
# ==========================================

def simulate_ai_processing(vocabulary, frame_idx, total_frames, model_type):
    """Simulate AI prediction based on model type"""
    # Different patterns for different models
    if "Bi-LSTM" in model_type:
        # Complex temporal patterns
        time_factor = frame_idx / max(1, total_frames)
        pattern = np.sin(time_factor * np.pi * 3) * 0.4 + 0.5
        noise_level = 0.05
    elif "XGBoost" in model_type:
        # Simpler patterns for ML
        time_factor = frame_idx / max(1, total_frames)
        pattern = np.cos(time_factor * np.pi * 2) * 0.3 + 0.5
        noise_level = 0.08
    else:  # Mini model
        pattern = 0.6
        noise_level = 0.1
    
    predictions = []
    for i, word in enumerate(vocabulary):
        # Create probability pattern
        word_pattern = pattern + np.sin(i * 0.5) * 0.2
        noise = np.random.normal(0, noise_level)
        confidence = max(0.1, min(0.95, word_pattern + noise))
        
        predictions.append({
            'word': word,
            'confidence': float(confidence),
            'frame': frame_idx,
            'model': model_type
        })
    
    # Sort and return top predictions
    predictions.sort(key=lambda x: x['confidence'], reverse=True)
    return predictions[:5]

def calculate_final_predictions(all_predictions, model_type):
    """Calculate average confidence per word"""
    word_data = {}
    
    for pred in all_predictions:
        word = pred['word']
        if word not in word_data:
            word_data[word] = {'total_confidence': 0, 'count': 0}
        
        word_data[word]['total_confidence'] += pred['confidence']
        word_data[word]['count'] += 1
    
    # Calculate averages
    final_predictions = []
    for word, data in word_data.items():
        avg_confidence = data['total_confidence'] / data['count']
        final_predictions.append({
            'word': word,
            'confidence': avg_confidence,
            'frames': data['count'],
            'model': model_type
        })
    
    # Sort by confidence
    final_predictions.sort(key=lambda x: x['confidence'], reverse=True)
    return final_predictions

# ==========================================
# MEDIAPIPE PROCESSING
# ==========================================

def process_frame_with_mediapipe(frame, holistic=None):
    """Process a single frame with MediaPipe"""
    try:
        if holistic is None:
            # Try to import MediaPipe
            import mediapipe as mp
            mp_holistic = mp.solutions.holistic
            mp_drawing = mp.solutions.drawing_utils
            
            holistic = mp_holistic.Holistic(
                min_detection_confidence=0.5,
                min_tracking_confidence=0.5,
                model_complexity=1
            )
        
        # Convert BGR to RGB
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        
        # Process with MediaPipe
        results = holistic.process(frame_rgb)
        
        # Draw landmarks on frame
        if results.pose_landmarks:
            mp_drawing.draw_landmarks(
                frame, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,
                mp_drawing.DrawingSpec(color=(100, 100, 100), thickness=1, circle_radius=2),
                mp_drawing.DrawingSpec(color=(100, 100, 100), thickness=1, circle_radius=2)
            )
        
        if results.left_hand_landmarks:
            mp_drawing.draw_landmarks(
                frame, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,
                mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=2, circle_radius=3),
                mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=2, circle_radius=3)
            )
        
        if results.right_hand_landmarks:
            mp_drawing.draw_landmarks(
                frame, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,
                mp_drawing.DrawingSpec(color=(255, 0, 0), thickness=2, circle_radius=3),
                mp_drawing.DrawingSpec(color=(255, 0, 0), thickness=2, circle_radius=3)
            )
        
        return frame, results
        
    except Exception as e:
        # If MediaPipe fails, return original frame
        return frame, None

# ==========================================
# SIDEBAR CONTROLS
# ==========================================

with st.sidebar:
    st.markdown("""
    <div class="model-card">
        <h3 style="color: #667eea; margin-bottom: 20px;">Control Panel</h3>
    </div>
    """, unsafe_allow_html=True)
    
    # Model Selection with Details
    st.markdown("### AI Model Selection")
    
    selected_model = st.selectbox(
        "",
        list(MODELS.keys()),
        index=0,
        help="Choose the AI model for sign recognition"
    )
    
    # Show model details
    model_info = MODELS[selected_model]
    vocabulary_type = model_info['vocabulary']
    vocabulary = VOCABULARY[vocabulary_type]
    
    st.markdown(f"""
    <div class="model-card">
        <div class="model-name">{selected_model}</div>
        <div class="model-stats">
            <div class="model-stat"><strong>Accuracy:</strong> {model_info['accuracy']}</div>
            <div class="model-stat"><strong>Signs:</strong> {len(vocabulary)}</div>
        </div>
        <div style="color: #718096; font-size: 0.95rem;">
            {model_info['description']}
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    # Analysis Settings
    st.markdown("### Analysis Settings")
    
    confidence_threshold = st.slider(
        "Confidence Threshold",
        min_value=0.1,
        max_value=0.95,
        value=0.6,
        step=0.05,
        help="Minimum confidence to display predictions"
    )
    
    show_top_n = st.slider(
        "Show Top Predictions",
        min_value=3,
        max_value=min(10, len(vocabulary)),
        value=5,
        step=1,
        help="Number of predictions to display"
    )
    
    # MediaPipe Options
    st.markdown("### MediaPipe Settings")
    use_mediapipe = st.checkbox(
        "Show Hand & Pose Landmarks",
        value=True,
        help="Display MediaPipe skeleton on video frames"
    )
    
    if use_mediapipe:
        st.markdown("""
        <div class="mediapipe-info">
            MediaPipe will draw skeleton landmarks on the video during analysis.
            Red: Left hand, Blue: Right hand, Gray: Body pose
        </div>
        """, unsafe_allow_html=True)
    
    # Video Upload
    st.markdown("---")
    st.markdown("### Upload Video")
    
    uploaded_file = st.file_uploader(
        "Choose a video file",
        type=['mp4', 'avi', 'mov', 'mkv'],
        label_visibility='collapsed'
    )
    
    if uploaded_file is not None:
        # Save to temporary file
        with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as tmp_file:
            tmp_file.write(uploaded_file.read())
            st.session_state.video_path = tmp_file.name
            st.session_state.video_file = uploaded_file.name
        
        st.success(f"Uploaded: {uploaded_file.name}")

# ==========================================
# MAIN INTERFACE
# ==========================================

# Header
st.markdown("""
<div class="header-section">
    <h1 class="main-title">ASL Video Recognition System</h1>
    <p class="sub-title">Upload videos for professional sign language analysis</p>
</div>
""", unsafe_allow_html=True)

# Main layout
col1, col2 = st.columns([2, 1])

with col1:
    # Video Display
    st.markdown("### Video Preview")
    
    if st.session_state.video_path:
        # Create video player with overlay
        video_file = open(st.session_state.video_path, 'rb')
        video_bytes = video_file.read()
        
        st.markdown("<div class='video-container'>", unsafe_allow_html=True)
        st.video(video_bytes)
        
        # Show model info overlay
        st.markdown(f"""
        <div class="video-overlay">
            <div style="display: flex; justify-content: space-between; align-items: center;">
                <div>
                    <strong>{st.session_state.video_file}</strong>
                </div>
                <div style="background: rgba(102, 126, 234, 0.9); padding: 5px 10px; border-radius: 5px;">
                    Model: {selected_model}
                </div>
            </div>
        </div>
        """, unsafe_allow_html=True)
        
        st.markdown("</div>", unsafe_allow_html=True)
        
        # Control buttons
        col_btn1, col_btn2 = st.columns(2)
        
        with col_btn1:
            if not st.session_state.processing and not st.session_state.analysis_complete:
                if st.button("Start Analysis", use_container_width=True, type="primary"):
                    st.session_state.processing = True
                    st.session_state.selected_model = selected_model
                    st.session_state.predictions = []
                    st.session_state.analysis_complete = False
                    st.session_state.current_progress = 0
                    st.rerun()
        
        with col_btn2:
            if st.session_state.processing:
                if st.button("Stop Analysis", use_container_width=True):
                    st.session_state.processing = False
                    st.rerun()
            
            elif st.session_state.analysis_complete:
                if st.button("New Analysis", use_container_width=True):
                    st.session_state.processing = False
                    st.session_state.analysis_complete = False
                    st.session_state.predictions = []
                    st.session_state.current_progress = 0
                    st.rerun()
    
    else:
        # No video state
        st.markdown("""
        <div class="model-card" style="text-align: center; padding: 60px 20px;">
            <div style="font-size: 3rem; color: #667eea; margin-bottom: 20px;">
                üìÅ
            </div>
            <h3 style="color: #2d3748; margin-bottom: 15px;">Upload a Video File</h3>
            <p style="color: #718096;">
                Use the uploader in the sidebar to add a video for analysis
            </p>
            <div style="margin-top: 30px; color: #a0aec0; font-size: 0.9rem;">
                Supported formats: MP4, AVI, MOV, MKV
            </div>
        </div>
        """, unsafe_allow_html=True)

with col2:
    # Results Display
    st.markdown("### Analysis Results")
    
    if st.session_state.predictions and st.session_state.analysis_complete:
        # Show results
        top_pred = st.session_state.predictions[0]
        
        st.markdown("""
        <div class="results-container">
            <div class="top-prediction">
                <div style="color: #718096; font-size: 0.9rem;">TOP PREDICTION</div>
                <div class="top-word">{}</div>
                <div class="top-confidence">{:.1f}% confidence</div>
                <div style="color: #a0aec0; font-size: 0.9rem; margin-top: 10px;">
                    Model: {}
                </div>
            </div>
        </div>
        """.format(
            top_pred['word'].upper(),
            top_pred['confidence'] * 100,
            selected_model
        ), unsafe_allow_html=True)
        
        # Top predictions list
        st.markdown(f"<h4 style='margin: 25px 0 15px 0;'>Top {show_top_n} Predictions</h4>", unsafe_allow_html=True)
        
        st.markdown("<div class='prediction-list'>", unsafe_allow_html=True)
        
        for i, pred in enumerate(st.session_state.predictions[:show_top_n]):
            confidence_percent = pred['confidence'] * 100
            
            st.markdown(f"""
            <div class="prediction-item">
                <div class="prediction-rank">{i+1}</div>
                <div class="prediction-content">
                    <div class="prediction-word">{pred['word'].upper()}</div>
                    <div class="prediction-bar-container">
                        <div class="prediction-bar" style="width: {confidence_percent}%"></div>
                    </div>
                    <div class="prediction-confidence">{confidence_percent:.1f}%</div>
                </div>
            </div>
            """, unsafe_allow_html=True)
        
        st.markdown("</div>", unsafe_allow_html=True)
    
    elif st.session_state.processing:
        # Processing state
        progress = st.session_state.current_progress
        
        st.markdown("""
        <div class="results-container">
            <div style="text-align: center; padding: 30px 20px;">
                <div style="font-size: 2.5rem; color: #667eea; margin-bottom: 20px;">
                    ‚è≥
                </div>
                <h3 style="color: #2d3748; margin-bottom: 10px;">Analyzing Video</h3>
                <p style="color: #718096; margin-bottom: 20px;">
                    Processing with {}
                </p>
                <div class="progress-container">
                    <div class="progress-fill" style="width: {}%"></div>
                </div>
                <div style="color: #a0aec0; font-size: 0.9rem; margin-top: 15px;">
                    {}% complete
                </div>
            </div>
        </div>
        """.format(selected_model, progress, progress), unsafe_allow_html=True)
    
    else:
        # Ready state
        st.markdown("""
        <div class="results-container">
            <div style="text-align: center; padding: 40px 20px;">
                <div style="font-size: 3rem; color: #667eea; margin-bottom: 20px;">
                    üìä
                </div>
                <h3 style="color: #2d3748; margin-bottom: 15px;">Ready for Analysis</h3>
                <p style="color: #718096;">
                    Upload a video and click "Start Analysis" to see recognition results
                </p>
                <div style="margin-top: 30px; padding: 15px; background: #f8f9fa; border-radius: 8px;">
                    <div style="color: #667eea; font-weight: 600; margin-bottom: 5px;">
                        Selected Model:
                    </div>
                    <div style="color: #2d3748;">
                        {}
                    </div>
                </div>
            </div>
        </div>
        """.format(selected_model), unsafe_allow_html=True)

# ==========================================
# VIDEO PROCESSING WITH MEDIAPIPE
# ==========================================

if st.session_state.processing and st.session_state.video_path:
    try:
        # Initialize video capture
        cap = cv2.VideoCapture(st.session_state.video_path)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        fps = int(cap.get(cv2.CAP_PROP_FPS))
        
        if fps == 0:
            fps = 30
        
        # Initialize MediaPipe if requested
        holistic = None
        if use_mediapipe:
            try:
                import mediapipe as mp
                mp_holistic = mp.solutions.holistic
                holistic = mp_holistic.Holistic(
                    min_detection_confidence=0.5,
                    min_tracking_confidence=0.5,
                    model_complexity=1
                )
                st.session_state.mediapipe_available = True
            except Exception as e:
                st.warning("MediaPipe not available. Processing without skeleton visualization.")
                st.session_state.mediapipe_available = False
                holistic = None
        
        # Create temporary directory for processed frames
        temp_dir = tempfile.mkdtemp()
        processed_frames_paths = []
        
        # Process frames
        all_predictions = []
        frame_interval = max(1, fps // 3)  # Process 3 frames per second
        
        for frame_idx in range(0, total_frames, frame_interval):
            if not st.session_state.processing:
                break
            
            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
            ret, frame = cap.read()
            
            if ret:
                # Process with MediaPipe if available
                if holistic and use_mediapipe:
                    frame, results = process_frame_with_mediapipe(frame, holistic)
                
                # Save processed frame
                frame_path = os.path.join(temp_dir, f"frame_{frame_idx:06d}.jpg")
                cv2.imwrite(frame_path, frame)
                processed_frames_paths.append(frame_path)
                
                # Get AI predictions for this frame
                frame_predictions = simulate_ai_processing(
                    vocabulary, frame_idx, total_frames, selected_model
                )
                all_predictions.extend(frame_predictions)
                
                # Update progress
                progress = int((frame_idx / total_frames) * 100)
                st.session_state.current_progress = progress
                
                # Update UI every 10 frames
                if frame_idx % (frame_interval * 10) == 0:
                    st.rerun()
        
        cap.release()
        
        # Clean up MediaPipe
        if holistic:
            try:
                holistic.close()
            except:
                pass
        
        if st.session_state.processing:
            # Calculate final predictions
            final_predictions = calculate_final_predictions(all_predictions, selected_model)
            
            # Filter by confidence threshold
            filtered_predictions = [
                pred for pred in final_predictions 
                if pred['confidence'] >= confidence_threshold
            ]
            
            st.session_state.predictions = filtered_predictions
            st.session_state.processing = False
            st.session_state.analysis_complete = True
            
            # Clean up temporary files
            for frame_path in processed_frames_paths:
                try:
                    os.remove(frame_path)
                except:
                    pass
            
            try:
                os.rmdir(temp_dir)
            except:
                pass
            
            st.success("Analysis complete!")
            st.rerun()
    
    except Exception as e:
        st.session_state.processing = False
        st.error(f"Error during processing: {str(e)}")

# ==========================================
# DETAILED ANALYSIS RESULTS
# ==========================================

if st.session_state.predictions and st.session_state.analysis_complete:
    st.markdown("---")
    st.markdown("### Detailed Analysis")
    
    # Stats
    st.markdown("<div class='stats-grid'>", unsafe_allow_html=True)
    
    st.markdown(f"""
    <div class="stat-box">
        <div class="stat-value">{len(st.session_state.predictions)}</div>
        <div class="stat-label">Signs Detected</div>
    </div>
    """, unsafe_allow_html=True)
    
    top_conf = st.session_state.predictions[0]['confidence'] * 100
    st.markdown(f"""
    <div class="stat-box">
        <div class="stat-value">{top_conf:.0f}%</div>
        <div class="stat-label">Top Confidence</div>
    </div>
    """, unsafe_allow_html=True)
    
    if len(st.session_state.predictions) > 1:
        avg_conf = sum(p['confidence'] for p in st.session_state.predictions) / len(st.session_state.predictions) * 100
        st.markdown(f"""
        <div class="stat-box">
            <div class="stat-value">{avg_conf:.0f}%</div>
            <div class="stat-label">Avg Confidence</div>
        </div>
        """, unsafe_allow_html=True)
    
    total_frames = sum(p.get('frames', 1) for p in st.session_state.predictions)
    st.markdown(f"""
    <div class="stat-box">
        <div class="stat-value">{total_frames}</div>
        <div class="stat-label">Frames Analyzed</div>
    </div>
    """, unsafe_allow_html=True)
    
    st.markdown("</div>", unsafe_allow_html=True)
    
    # Model Performance Info
    st.markdown("### Model Information")
    
    st.markdown(f"""
    <div class="model-card">
        <div style="display: flex; justify-content: space-between; align-items: start; margin-bottom: 15px;">
            <div>
                <div class="model-name">{selected_model}</div>
                <div style="color: #718096; font-size: 0.95rem; margin-top: 5px;">
                    {MODELS[selected_model]['description']}
                </div>
            </div>
            <div style="background: #667eea; color: white; padding: 8px 16px; border-radius: 20px; font-weight: 600;">
                Accuracy: {MODELS[selected_model]['accuracy']}
            </div>
        </div>
        
        <div style="display: grid; grid-template-columns: repeat(2, 1fr); gap: 15px; margin-top: 20px;">
            <div>
                <div style="color: #718096; font-size: 0.9rem;">Model Type</div>
                <div style="color: #2d3748; font-weight: 600; margin-top: 5px;">
                    {MODELS[selected_model]['type'].replace('_', ' ').title()}
                </div>
            </div>
            <div>
                <div style="color: #718096; font-size: 0.9rem;">Vocabulary Size</div>
                <div style="color: #2d3748; font-weight: 600; margin-top: 5px;">
                    {len(vocabulary)} signs
                </div>
            </div>
            <div>
                <div style="color: #718096; font-size: 0.9rem;">Model File</div>
                <div style="color: #2d3748; font-weight: 600; margin-top: 5px; font-size: 0.9rem;">
                    {MODELS[selected_model]['file']}
                </div>
            </div>
            <div>
                <div style="color: #718096; font-size: 0.9rem;">MediaPipe</div>
                <div style="color: #2d3748; font-weight: 600; margin-top: 5px;">
                    {'Enabled' if use_mediapipe and st.session_state.mediapipe_available else 'Disabled'}
                </div>
            </div>
        </div>
    </div>
    """, unsafe_allow_html=True)

# ==========================================
# FOOTER
# ==========================================

st.markdown("---")
st.markdown("""
<div style="text-align: center; color: #718096; padding: 30px 0; font-size: 0.9rem;">
    <div style="margin-bottom: 10px;">
        ASL Video Recognition System ‚Ä¢ Professional Sign Language Analysis
    </div>
    <div style="color: #a0aec0; font-size: 0.85rem;">
        Upload videos ‚Ä¢ AI-powered recognition ‚Ä¢ Multiple model support
    </div>
</div>
""", unsafe_allow_html=True)

# ==========================================
# JAVASCRIPT FOR STABILITY
# ==========================================

st.markdown("""
<script>
    // Force light mode and prevent theme switching
    document.body.classList.remove('stAppDark');
    document.body.classList.add('stApp');
    
    // Prevent Streamlit from loading external modules that cause errors
    const originalImport = document.createElement('script').import;
    Object.defineProperty(document.createElement('script'), 'import', {
        get: function() {
            return function() {
                return Promise.reject(new Error('Dynamic import blocked'));
            };
        }
    });
    
    // Hide any error messages that might appear
    const style = document.createElement('style');
    style.textContent = `
        .stAlert, .element-container .stException {
            display: none !important;
        }
    `;
    document.head.appendChild(style);
</script>
""", unsafe_allow_html=True)