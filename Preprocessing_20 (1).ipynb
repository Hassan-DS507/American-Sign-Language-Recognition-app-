{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qiu-fH9eGETq",
        "outputId": "93291941-6b24-4fc7-8ee6-3c9b84e21664"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NmywEiZHZP-5",
        "outputId": "a58243fc-25a0-4179-9bd8-d4034a9a6594"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.10.21-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (25.4.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (25.9.23)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.12/dist-packages (from mediapipe) (0.7.2)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.12/dist-packages (from mediapipe) (0.7.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from mediapipe) (3.10.0)\n",
            "Collecting numpy<2 (from mediapipe)\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.12/dist-packages (from mediapipe) (4.12.0.88)\n",
            "Collecting protobuf<5,>=4.25.3 (from mediapipe)\n",
            "  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
            "  Downloading sounddevice-0.5.3-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from mediapipe) (0.2.1)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.12/dist-packages (from sounddevice>=0.4.4->mediapipe) (2.0.0)\n",
            "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe) (0.5.4)\n",
            "INFO: pip is looking at multiple versions of jax to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting jax (from mediapipe)\n",
            "  Downloading jax-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting jaxlib (from mediapipe)\n",
            "  Downloading jaxlib-0.8.1-cp312-cp312-manylinux_2_27_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting jax (from mediapipe)\n",
            "  Downloading jax-0.8.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting jaxlib (from mediapipe)\n",
            "  Downloading jaxlib-0.8.0-cp312-cp312-manylinux_2_27_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting jax (from mediapipe)\n",
            "  Downloading jax-0.7.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting jaxlib (from mediapipe)\n",
            "  Downloading jaxlib-0.7.1-cp312-cp312-manylinux_2_27_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.12 in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe) (1.16.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
            "INFO: pip is looking at multiple versions of opencv-contrib-python to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting opencv-contrib-python (from mediapipe)\n",
            "  Downloading opencv_contrib_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.23)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n",
            "Downloading mediapipe-0.10.21-cp312-cp312-manylinux_2_28_x86_64.whl (35.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.6/35.6 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sounddevice-0.5.3-py3-none-any.whl (32 kB)\n",
            "Downloading jax-0.7.1-py3-none-any.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jaxlib-0.7.1-cp312-cp312-manylinux_2_27_x86_64.whl (81.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.2/81.2 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_contrib_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (69.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: protobuf, numpy, sounddevice, opencv-contrib-python, jaxlib, jax, mediapipe\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.5\n",
            "    Uninstalling protobuf-5.29.5:\n",
            "      Successfully uninstalled protobuf-5.29.5\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: opencv-contrib-python\n",
            "    Found existing installation: opencv-contrib-python 4.12.0.88\n",
            "    Uninstalling opencv-contrib-python-4.12.0.88:\n",
            "      Successfully uninstalled opencv-contrib-python-4.12.0.88\n",
            "  Attempting uninstall: jaxlib\n",
            "    Found existing installation: jaxlib 0.7.2\n",
            "    Uninstalling jaxlib-0.7.2:\n",
            "      Successfully uninstalled jaxlib-0.7.2\n",
            "  Attempting uninstall: jax\n",
            "    Found existing installation: jax 0.7.2\n",
            "    Uninstalling jax-0.7.2:\n",
            "      Successfully uninstalled jax-0.7.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opentelemetry-proto 1.37.0 requires protobuf<7.0,>=5.0, but you have protobuf 4.25.8 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed jax-0.7.1 jaxlib-0.7.1 mediapipe-0.10.21 numpy-1.26.4 opencv-contrib-python-4.11.0.86 protobuf-4.25.8 sounddevice-0.5.3\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "7a57a9db19f64c49909df2711a293d4a",
              "pip_warning": {
                "packages": [
                  "google",
                  "numpy"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pip install mediapipe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "eL8WUcgsHf6p",
        "outputId": "6ac907a6-f894-4f30-aad2-23d5b859a02c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total videos to process: 744\n",
            "Classes: ['erase', 'shave', 'catch', 'drown', 'envelope', 'cool', 'cry', 'pineapple', 'follow', 'pop', 'banana', 'sandwich', 'jacket', 'strawberry', 'cloud', 'fork', 'dog', 'necklace', 'handsome', 'bury']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/744 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Sample video path: /content/drive/MyDrive/weasel/ASL-Project/Data/dataset/row_data(videos)/part_10/pineapple_20241119_172633.mp4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 1/744 [00:56<11:42:50, 56.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Could not process or found no frames for /content/drive/MyDrive/weasel/ASL-Project/Data/dataset/row_data(videos)/part_10/pineapple_20241119_172633.mp4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|█▉        | 147/744 [22:40<3:22:38, 20.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Could not process or found no frames for /content/drive/MyDrive/weasel/ASL-Project/Data/dataset/row_data(videos)/part_7/cry_20241119_172639.mp4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 448/744 [1:05:42<1:45:06, 21.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Could not process or found no frames for /content/drive/MyDrive/weasel/ASL-Project/Data/dataset/row_data(videos)/part_8/follow_20241119_172643_112.mp4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 744/744 [1:49:25<00:00,  8.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✅ Processing Complete!\n",
            "Data saved to: /content/drive/MyDrive/weasel/try_20Word \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import mediapipe as mp\n",
        "from tqdm import tqdm  # For progress bar\n",
        "from google.colab import drive\n",
        "\n",
        "# ==========================================\n",
        "# 1. Configuration & Drive Setup\n",
        "# ==========================================\n",
        "\n",
        "# Mount Drive (if not already mounted)\n",
        "if not os.path.exists('/content/drive'):\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "CSV_PATH = '/content/part_2.csv'   # Path to your metadata CSV\n",
        "OUTPUT_DIR = '/content/drive/MyDrive/weasel/try_20Word ' # Where to save output\n",
        "SEQUENCE_LENGTH = 50             # Fixed frame count\n",
        "# انسخ القائمة دي وحطها مكان القائمة القديمة في كود V3\n",
        "TARGET_CLASSES = [\n",
        "    'erase', 'shave', 'catch', 'drown', 'envelope',\n",
        "    'cool', 'cry', 'pineapple', 'follow', 'pop',\n",
        "    'banana', 'sandwich', 'jacket', 'strawberry', 'cloud',\n",
        "    'fork', 'dog', 'necklace', 'handsome', 'bury'\n",
        "] # The 5 selected classes\n",
        "\n",
        "VIDEO_BASE_PATH = os.path.dirname(CSV_PATH) # This sets the base to the folder containing the CSV\n",
        "\n",
        "# Create Output Directory\n",
        "if not os.path.exists(OUTPUT_DIR):\n",
        "    os.makedirs(OUTPUT_DIR)\n",
        "\n",
        "# ==========================================\n",
        "# 2. Advanced Preprocessing Logic (The Core)\n",
        "# ==========================================\n",
        "\n",
        "mp_holistic = mp.solutions.holistic\n",
        "\n",
        "def normalize_hand(pts):\n",
        "    \"\"\"\n",
        "    Normalizes hand landmarks relative to the wrist (point 0).\n",
        "    Scale is determined by the distance between wrist and middle finger MCP (point 9).\n",
        "    \"\"\"\n",
        "    ref = pts[0].copy() # Wrist\n",
        "    scale = np.linalg.norm(pts[9] - ref)\n",
        "    if scale < 1e-6: scale = 1.0\n",
        "    return (pts - ref) / scale\n",
        "\n",
        "def compute_torso_stats(pose_landmarks):\n",
        "    \"\"\"\n",
        "    Computes the torso center and scale (shoulder width or hip width)\n",
        "    to make the data invariant to camera distance and user position.\n",
        "    \"\"\"\n",
        "    torso_center = np.array([0.5, 0.5], dtype=np.float32)\n",
        "    torso_scale = 1.0\n",
        "\n",
        "    try:\n",
        "        ps = pose_landmarks\n",
        "        def get_xy(idx):\n",
        "            lm = ps.landmark[idx]\n",
        "            return np.array([lm.x, lm.y], dtype=np.float32)\n",
        "\n",
        "        left_sh, right_sh = get_xy(11), get_xy(12)\n",
        "        left_hip, right_hip = get_xy(23), get_xy(24)\n",
        "\n",
        "        # Calculate Center\n",
        "        shoulder_center = (left_sh + right_sh) / 2.0\n",
        "        hip_center = (left_hip + right_hip) / 2.0\n",
        "        torso_center = (shoulder_center + hip_center) / 2.0\n",
        "\n",
        "        # Calculate Scale\n",
        "        shoulder_dist = np.linalg.norm(left_sh - right_sh)\n",
        "        hip_dist = np.linalg.norm(left_hip - right_hip)\n",
        "        torso_scale = max(shoulder_dist, hip_dist, 1e-6)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    return torso_center, float(torso_scale)\n",
        "\n",
        "def extract_features_from_frame(results):\n",
        "    \"\"\"\n",
        "    Extracts 198 features:\n",
        "    - Pose: 33 points (x, y) normalized by torso.\n",
        "    - Hands: 21 points (x, y, z) normalized by wrist + wrist relative pos.\n",
        "    \"\"\"\n",
        "    feat = np.zeros(198, dtype=np.float32)\n",
        "\n",
        "    # --- 1. POSE ---\n",
        "    torso_center = np.array([0.5, 0.5], dtype=np.float32)\n",
        "    torso_scale = 1.0\n",
        "\n",
        "    if results.pose_landmarks:\n",
        "        torso_center, torso_scale = compute_torso_stats(results.pose_landmarks)\n",
        "        pose_xy = np.array([[lm.x, lm.y] for lm in results.pose_landmarks.landmark], dtype=np.float32)\n",
        "        # Normalize: (Point - Center) / Scale\n",
        "        pose_norm = (pose_xy - torso_center[None, :]) / torso_scale\n",
        "        feat[0:66] = pose_norm.flatten()\n",
        "\n",
        "    # --- 2. LEFT HAND ---\n",
        "    start_idx = 66\n",
        "    if results.left_hand_landmarks:\n",
        "        l_pts = np.array([[lm.x, lm.y, lm.z] for lm in results.left_hand_landmarks.landmark], dtype=np.float32)\n",
        "        # Shape features (63)\n",
        "        feat[start_idx : start_idx+63] = normalize_hand(l_pts)[:, :3].flatten()\n",
        "        # Relative Wrist Position (3)\n",
        "        wrist = l_pts[0]\n",
        "        wrist_rel = np.array([\n",
        "            (wrist[0] - torso_center[0]) / torso_scale,\n",
        "            (wrist[1] - torso_center[1]) / torso_scale,\n",
        "            wrist[2] / max(torso_scale, 1e-6)\n",
        "        ], dtype=np.float32)\n",
        "        feat[start_idx+63 : start_idx+66] = wrist_rel\n",
        "\n",
        "    # --- 3. RIGHT HAND ---\n",
        "    start_idx += 66\n",
        "    if results.right_hand_landmarks:\n",
        "        r_pts = np.array([[lm.x, lm.y, lm.z] for lm in results.right_hand_landmarks.landmark], dtype=np.float32)\n",
        "        # Shape features (63)\n",
        "        feat[start_idx : start_idx+63] = normalize_hand(r_pts)[:, :3].flatten()\n",
        "        # Relative Wrist Position (3)\n",
        "        wrist = r_pts[0]\n",
        "        wrist_rel = np.array([\n",
        "            (wrist[0] - torso_center[0]) / torso_scale,\n",
        "            (wrist[1] - torso_center[1]) / torso_scale,\n",
        "            wrist[2] / max(torso_scale, 1e-6)\n",
        "        ], dtype=np.float32)\n",
        "        feat[start_idx+63 : start_idx+66] = wrist_rel\n",
        "\n",
        "    return feat\n",
        "\n",
        "def process_video_pipeline(video_path):\n",
        "    \"\"\"\n",
        "    Full pipeline: Read Video -> MediaPipe -> Normalize -> Interpolate -> Pad\n",
        "    \"\"\"\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        return None\n",
        "\n",
        "    frames_buffer = []\n",
        "\n",
        "    with mp_holistic.Holistic(static_image_mode=False, min_detection_confidence=0.5) as holistic:\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret: break\n",
        "\n",
        "            # Convert to RGB\n",
        "            img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            results = holistic.process(img_rgb)\n",
        "\n",
        "            # Extract\n",
        "            features = extract_features_from_frame(results)\n",
        "\n",
        "            # Simple check: if frame is empty (all zeros), we might mark it as None to interpolate later\n",
        "            # For simplicity here, we append whatever we got.\n",
        "            # Ideally, you check if sum() == 0 to handle dropouts.\n",
        "            if np.sum(np.abs(features)) < 1e-6:\n",
        "                frames_buffer.append(None)\n",
        "            else:\n",
        "                frames_buffer.append(features)\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "    if not frames_buffer:\n",
        "        return None\n",
        "\n",
        "    # --- Interpolation (Filling missing frames) ---\n",
        "    # Convert list to array logic manually or via pandas\n",
        "    # Simple forward/backward fill logic:\n",
        "    for i in range(len(frames_buffer)):\n",
        "        if frames_buffer[i] is None:\n",
        "            # Find previous valid\n",
        "            prev_valid = next((frames_buffer[j] for j in range(i-1, -1, -1) if frames_buffer[j] is not None), None)\n",
        "            # Find next valid\n",
        "            next_valid = next((frames_buffer[j] for j in range(i+1, len(frames_buffer)) if frames_buffer[j] is not None), None)\n",
        "\n",
        "            if prev_valid is not None and next_valid is not None:\n",
        "                frames_buffer[i] = (prev_valid + next_valid) / 2.0\n",
        "            elif prev_valid is not None:\n",
        "                frames_buffer[i] = prev_valid\n",
        "            elif next_valid is not None:\n",
        "                frames_buffer[i] = next_valid\n",
        "            else:\n",
        "                frames_buffer[i] = np.zeros(198, dtype=np.float32)\n",
        "\n",
        "    # Convert to Numpy\n",
        "    data_array = np.array(frames_buffer, dtype=np.float32)\n",
        "\n",
        "    # --- Resampling / Padding to 50 Frames ---\n",
        "    current_len = len(data_array)\n",
        "    if current_len == SEQUENCE_LENGTH:\n",
        "        final_data = data_array\n",
        "    elif current_len < SEQUENCE_LENGTH:\n",
        "        # Pad with zeros at the end\n",
        "        padding = np.zeros((SEQUENCE_LENGTH - current_len, 198), dtype=np.float32)\n",
        "        final_data = np.vstack([data_array, padding])\n",
        "    else:\n",
        "        # Uniform Sampling (downsample)\n",
        "        indices = np.linspace(0, current_len - 1, SEQUENCE_LENGTH, dtype=int)\n",
        "        final_data = data_array[indices]\n",
        "\n",
        "    return final_data\n",
        "\n",
        "# ==========================================\n",
        "# 3. Main Execution Loop (With Checkpointing)\n",
        "# ==========================================\n",
        "\n",
        "def run_processing():\n",
        "    # 1. Load Metadata\n",
        "    df = pd.read_csv(CSV_PATH)\n",
        "\n",
        "    # 2. Filter for Target Classes\n",
        "    # Assuming the column name is 'word' based on previous context\n",
        "    subset_df = df[df['word'].isin(TARGET_CLASSES)].copy()\n",
        "\n",
        "    print(f\"Total videos to process: {len(subset_df)}\")\n",
        "    print(f\"Classes: {TARGET_CLASSES}\")\n",
        "\n",
        "    # 3. Iterate and Process\n",
        "    # We use tqdm for a progress bar\n",
        "    for idx, row in tqdm(subset_df.iterrows(), total=len(subset_df)):\n",
        "\n",
        "        word = row['word']\n",
        "        # --- MODIFICATION START ---\n",
        "        # Construct the full video path using the VIDEO_BASE_PATH\n",
        "        video_path = os.path.join(VIDEO_BASE_PATH, row['full_path'])\n",
        "\n",
        "        # Print the first video path to help debug if needed\n",
        "        if idx == 0:\n",
        "            print(f\"\\nSample video path: {video_path}\")\n",
        "        # --- MODIFICATION END ---\n",
        "\n",
        "        # Prepare Output Path\n",
        "        class_dir = os.path.join(OUTPUT_DIR, word)\n",
        "        if not os.path.exists(class_dir):\n",
        "            os.makedirs(class_dir)\n",
        "\n",
        "        # Create a unique filename (using video name or index)\n",
        "        # Assuming there is a 'video_name' or unique ID column. If not, use index.\n",
        "        vid_name = os.path.basename(video_path).split('.')[0]\n",
        "        save_path = os.path.join(class_dir, f\"{vid_name}.npy\")\n",
        "\n",
        "        # --- CHECKPOINTING ---\n",
        "        # If file exists, skip it (Resume capability)\n",
        "        if os.path.exists(save_path):\n",
        "            continue\n",
        "\n",
        "        # Process\n",
        "        try:\n",
        "            processed_data = process_video_pipeline(video_path)\n",
        "\n",
        "            if processed_data is not None:\n",
        "                np.save(save_path, processed_data)\n",
        "            else:\n",
        "                print(f\"Warning: Could not process or found no frames for {video_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {video_path}: {e}\")\n",
        "\n",
        "    print(\"\\n✅ Processing Complete!\")\n",
        "    print(f\"Data saved to: {OUTPUT_DIR}\")\n",
        "\n",
        "# Run the script\n",
        "if __name__ == \"__main__\":\n",
        "    run_processing()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}